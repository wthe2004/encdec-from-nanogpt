{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10f380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwt-wsl-ubt/codespace/toy-codes-hwt/encdec-from-nanogpt/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['lp', 'src', 'mt', 'ref', 'raw', 'annotators', 'domain', 'year', 'task', 'sys_id'],\n",
      "        num_rows: 12480\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 正确的方式：即使是从本地加载，也要添加 trust_remote_code=True\n",
    "dataset = load_dataset(\n",
    "    \"IWSLT/da2023\",\n",
    ")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661df1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lp': 'en-de', 'src': 'Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.', 'mt': 'Anschließend wendet C-E-A-S den Generator unabhängig voneinander auf die vier Etikettendokumente an und erzeugt für jede Klasse Freisetzungsnotizen.', 'ref': 'Dann wendet CEAS den Generator auf die vier markierten Dokumente unabhängig voneinander an und erstellt Versionshinweise für jede Klasse.', 'raw': 80, 'annotators': 1, 'domain': 'ACL', 'year': 2023, 'task': 'multilingual', 'sys_id': 2}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e248e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建一个迭代器，用于逐批提供文本数据\n",
    "def batch_iterator(batch_size=1000):\n",
    "    for i in range(0, len(dataset[\"train\"]), batch_size):\n",
    "        batch = dataset[\"train\"][i : i + batch_size]\n",
    "        # 从'src'和'ref'列中提取文本\n",
    "        yield [text for text in batch[\"src\"] if text is not None]\n",
    "        yield [text for text in batch[\"ref\"] if text is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc2a7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "# 1. 初始化一个分词器\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "\n",
    "# 2. 设置前置分词器（pre-tokenizer），这里我们使用空格分词\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "# 3. 初始化一个训练器\n",
    "# vocab_size: 词汇表大小\n",
    "# special_tokens: 特殊标记\n",
    "trainer = BpeTrainer(vocab_size=30000, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "\n",
    "# 4. 训练分词器\n",
    "tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)\n",
    "\n",
    "# 5. 保存训练好的分词器\n",
    "tokenizer.save(\"iwslt-da2023-bpe-tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9eb58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encdec-from-nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
